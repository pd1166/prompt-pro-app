import streamlit as st
import google.generativeai as genai
import time
import pandas as pd
from datetime import datetime

# ==========================================
# 1. 专转 转爪专
# ==========================================
st.set_page_config(
    page_title="Prompt Engineer Pro V10",
    page_icon="",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ==========================================
# 2. 转拽 CSS "专专" (Surgical Fix)
# ==========================================
st.markdown("""
    <style>
        /* 砖专 转 注驻转 专砖转 专   砖专 转 注 */
        .stApp {
            direction: ltr; 
            background-color: #FAFAFA;
        }
        
        /* 驻 专拽 转 拽住 驻 */
        .element-container, .stMarkdown, h1, h2, h3, h4, h5, h6, p {
            direction: rtl;
            text-align: right;
        }
        
        /* 转拽 住驻爪驻 砖转 拽 */
        .stTextInput input, .stTextArea textarea {
            direction: rtl;
            text-align: right;
        }
        
        /* 砖专 转驻专 驻转 */
        .stSelectbox div[data-baseweb="select"] > div {
            direction: rtl;
            text-align: right;
        }
        
        /* 砖专 住专 爪 */
        section[data-testid="stSidebar"] > div {
            direction: rtl;
            text-align: right;
        }
        
        /* 驻转专 专砖 */
        .stButton button { 
            width: 100%;
            border-radius: 10px;
            height: 50px;
            font-weight: bold;
            background: linear-gradient(90deg, #4B4BFF 0%, #0068C9 100%);
            color: white;
            border: none;
        }

        /* 住转专转 专 转专 */
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        header {visibility: hidden;} /* 住转专 转 驻住 爪注 注 砖转拽注 */
        
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 3.  专
# ==========================================
if 'history' not in st.session_state:
    st.session_state.history = []

def add_to_history(original_request, refined_prompt, model_rec, used_model):
    timestamp = datetime.now().strftime("%H:%M")
    st.session_state.history.insert(0, {
        "time": timestamp,
        "original": original_request,
        "prompt": refined_prompt,
        "recommendation": model_rec,
        "engine": used_model
    })

# ==========================================
# 4. 拽 注住拽转
# ==========================================
CONTEXT_LOGIC = {
    "砖拽 拽驻专": "Expert Copywriter. Focus: Psychology, Virality.",
    "转转 拽 驻转": "Software Architect. Focus: Clean Code, Security.",
    "转 爪专转": "Storyteller. Focus: Narrative depth.",
    "住专 注住拽转": "Consultant. Focus: Growth, ROI.",
    "/专": "Prompt Engineer. Focus: Clarity."
}

MODEL_LINKS = {
    "Claude": "https://claude.ai",
    "GPT": "https://chat.openai.com",
    "Gemini": "https://gemini.google.com"
}

def get_model_link_button(analysis_text):
    target_url = "https://chat.openai.com"
    label = "ChatGPT"
    if "Claude" in analysis_text:
        target_url = MODEL_LINKS["Claude"]
        label = "Claude AI"
    elif "Gemini" in analysis_text:
        target_url = MODEL_LINKS["Gemini"]
        label = "Gemini"
    return target_url, label

def get_api_key():
    try: return st.secrets["GEMINI_API_KEY"]
    except: return ""

def get_safe_model():
    try: return 'gemini-1.5-flash'
    except: return 'gemini-pro'

def clean_response(text):
    return text.replace("undefined", "").replace("null", "").strip()

def generate_smart_prompt(api_key, raw_input, context_key, tone):
    try:
        genai.configure(api_key=api_key.strip())
        model_name = get_safe_model()
        model = genai.GenerativeModel(model_name)
        specific_logic = CONTEXT_LOGIC.get(context_key, CONTEXT_LOGIC["/专"])

        full_query = f"""
        Act as a world-class Meta-Prompting System (CO-STAR framework).
        INPUT: Request="{raw_input}", Persona="{specific_logic}", Tone="{tone}".
        TASK:
        1. Write an expert prompt in Hebrew.
        2. Recommend best AI model (Claude/GPT/Gemini).
        OUTPUT FORMAT:
        ---DIVIDER---
        [Hebrew Prompt]
        ---DIVIDER---
        [Recommendation]
        """
        
        response = model.generate_content(full_query)
        return clean_response(response.text), model_name
    except Exception as e:
        if "429" in str(e): return "QUOTA_ERROR", ""
        return f"Error: {str(e)}", ""

# ==========================================
# 5. 砖拽 砖转砖
# ==========================================
saved_key = get_api_key()

# 住专 爪
with st.sidebar:
    st.title("锔 专转")
    if saved_key:
        st.success("驻转 专")
        api_key = saved_key
    else:
        api_key = st.text_input("驻转 API", type="password")
    
    selected_context = st.selectbox("转:", list(CONTEXT_LOGIC.keys()))
    selected_tone = st.select_slider(":", ["专砖", "砖专", "爪专转", "砖拽"], value="专砖")
    
    st.markdown("---")
    # 住专 拽爪专转
    if st.session_state.history:
        st.caption("住专:")
        for item in st.session_state.history[:3]:
            st.text(f" {item['time']}")
            st.code(item['prompt'][:50] + "...", language="markdown")

# 住 专砖
st.title("Prompt Pro V10 ")
st.markdown("#####  驻专驻 拽爪注 (专住 爪)")

user_input = st.text_area(" 砖 砖?", height=100, placeholder="砖: 驻住 拽 注 AI...")

if st.button("爪专 驻专驻 "):
    if not api_key or not user_input:
        st.error("住专 驻转  拽住")
    else:
        with st.spinner("注..."):
            result, used_model = generate_smart_prompt(api_key, user_input, selected_context, selected_tone)
            
            if result == "QUOTA_ERROR":
                st.warning("注住 专注, 住 砖.")
            elif "Error" in result:
                st.error(result)
            else:
                parts = result.split("---DIVIDER---")
                prompt_content = parts[1] if len(parts) > 1 else result
                analysis_content = parts[2] if len(parts) > 2 else " 爪."
                
                add_to_history(user_input, prompt_content, analysis_content, used_model)
                
                st.success("!")
                st.code(prompt_content.strip(), language="markdown")
                
                url, label = get_model_link_button(analysis_content)
                st.link_button(f"驻转 -{label}", url, use_container_width=True)
