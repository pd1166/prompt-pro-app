import streamlit as st
import google.generativeai as genai
import time
import pandas as pd
from datetime import datetime

# ==========================================
# 1. 专转 转爪专
# ==========================================
st.set_page_config(
    page_title="Prompt Engineer Pro V11",
    page_icon="",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ==========================================
# 2. 转拽 注爪 (Layout Fix)
# ==========================================
st.markdown("""
    <style>
        .stApp { direction: ltr; background-color: #FAFAFA; }
        .element-container, .stMarkdown, h1, h2, h3, h4, h5, h6, p { direction: rtl; text-align: right; }
        .stTextInput input, .stTextArea textarea { direction: rtl; text-align: right; }
        .stSelectbox div[data-baseweb="select"] > div { direction: rtl; text-align: right; }
        section[data-testid="stSidebar"] > div { direction: rtl; text-align: right; }
        .stButton button { width: 100%; border-radius: 10px; height: 50px; font-weight: bold; background: linear-gradient(90deg, #4B4BFF 0%, #0068C9 100%); color: white; border: none; }
        #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 3.  专
# ==========================================
if 'history' not in st.session_state:
    st.session_state.history = []

def add_to_history(original_request, refined_prompt, model_rec, used_model):
    timestamp = datetime.now().strftime("%H:%M")
    st.session_state.history.insert(0, {
        "time": timestamp,
        "original": original_request,
        "prompt": refined_prompt,
        "recommendation": model_rec,
        "engine": used_model
    })

# ==========================================
# 4. 拽 注住拽转 + 专转  
# ==========================================
CONTEXT_LOGIC = {
    "砖拽 拽驻专": "Expert Copywriter. Focus: Psychology, Virality.",
    "转转 拽 驻转": "Software Architect. Focus: Clean Code, Security.",
    "转 爪专转": "Storyteller. Focus: Narrative depth.",
    "住专 注住拽转": "Consultant. Focus: Growth, ROI.",
    "/专": "Prompt Engineer. Focus: Clarity."
}

MODEL_LINKS = {
    "Claude": "https://claude.ai",
    "GPT": "https://chat.openai.com",
    "Gemini": "https://gemini.google.com"
}

def get_model_link_button(analysis_text):
    target_url = "https://chat.openai.com"
    label = "ChatGPT"
    if "Claude" in analysis_text:
        target_url = MODEL_LINKS["Claude"]
        label = "Claude AI"
    elif "Gemini" in analysis_text:
        target_url = MODEL_LINKS["Gemini"]
        label = "Gemini"
    return target_url, label

def get_api_key():
    try: return st.secrets["GEMINI_API_KEY"]
    except: return ""

def get_working_model():
    """
    驻拽爪  砖拽转   转 拽 砖
     砖转 砖转.
    """
    try:
        # 1. 拽砖转 专砖转  砖专转
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # 2. 驻砖 驻 住专 注驻转
        # 注驻转 专砖: 驻砖 1.5 (专 )
        for m in models:
            if 'gemini-1.5-flash' in m: return m
            
        # 注驻转 砖: 驻专 1.5 (拽)
        for m in models:
            if 'gemini-1.5-pro' in m: return m
            
        # 注驻转 砖砖转: 驻专 专 (砖 )
        for m in models:
            if 'gemini-pro' in m: return m
            
        #   爪  专, 专 转 专砖 专砖
        if models:
            return models[0]
            
        return 'gemini-1.5-flash' # 专专转  拽专 拽爪
    except:
        return 'gemini-pro' # Fallback 专 

def clean_response(text):
    return text.replace("undefined", "").replace("null", "").strip()

def generate_smart_prompt(api_key, raw_input, context_key, tone):
    try:
        genai.configure(api_key=api_key.strip())
        
        # 专转  转
        model_name = get_working_model()
        model = genai.GenerativeModel(model_name)
        
        specific_logic = CONTEXT_LOGIC.get(context_key, CONTEXT_LOGIC["/专"])

        full_query = f"""
        Act as a world-class Meta-Prompting System (CO-STAR framework).
        INPUT: Request="{raw_input}", Persona="{specific_logic}", Tone="{tone}".
        TASK:
        1. Write an expert prompt in Hebrew.
        2. Recommend best AI model (Claude/GPT/Gemini).
        OUTPUT FORMAT:
        ---DIVIDER---
        [Hebrew Prompt]
        ---DIVIDER---
        [Recommendation]
        """
        
        response = model.generate_content(full_query)
        return clean_response(response.text), model_name
    except Exception as e:
        if "429" in str(e): return "QUOTA_ERROR", ""
        return f"Error: {str(e)}", ""

# ==========================================
# 5. 砖拽 砖转砖
# ==========================================
saved_key = get_api_key()

# 住专 爪
with st.sidebar:
    st.title("锔 专转")
    if saved_key:
        st.success("驻转 专")
        api_key = saved_key
    else:
        api_key = st.text_input("驻转 API", type="password")
    
    selected_context = st.selectbox("转:", list(CONTEXT_LOGIC.keys()))
    selected_tone = st.select_slider(":", ["专砖", "砖专", "爪专转", "砖拽"], value="专砖")
    
    st.markdown("---")
    if st.session_state.history:
        st.caption("住专 专:")
        for item in st.session_state.history[:3]:
            st.text(f" {item['time']}")
            st.code(item['prompt'][:40] + "...", language="markdown")

# 住 专砖
st.title("Prompt Pro V11 ")
st.markdown("#####  驻专驻  ( )")

user_input = st.text_area(" 砖 砖?", height=100, placeholder="砖: 驻住 拽 注 AI...")

if st.button("爪专 驻专驻 "):
    if not api_key or not user_input:
        st.error("住专 驻转  拽住")
    else:
        with st.spinner("驻砖   注..."):
            result, used_model = generate_smart_prompt(api_key, user_input, selected_context, selected_tone)
            
            if result == "QUOTA_ERROR":
                st.warning("注住 专注 注  . 住 砖 注 拽.")
            elif "Error" in result:
                st.error(f"砖: {result}")
                st.info("住 爪专 驻转 API 砖 -Google AI Studio   砖.")
            else:
                parts = result.split("---DIVIDER---")
                prompt_content = parts[1] if len(parts) > 1 else result
                analysis_content = parts[2] if len(parts) > 2 else " 爪."
                
                add_to_history(user_input, prompt_content, analysis_content, used_model)
                
                st.success(f"爪注 爪注转: {used_model}")
                st.code(prompt_content.strip(), language="markdown")
                
                url, label = get_model_link_button(analysis_content)
                st.link_button(f"驻转 -{label}", url, use_container_width=True)
